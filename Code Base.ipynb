{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Récolte des données\n",
    "La création de nos bases de données va se faire en plusieurs étapes. Dans un premier temps nous allons récupérer les données des trotinnettes présentes à Paris et celle des métro et rer à paris. Ensuite nous allons calculer la distance des trotinnettes aux moyens de transport en commun. Aussi nous allons récupérer toutes des données socio-démographique de la ville de Paris par quartier admnistratifs. Les deux bases finales contiennent pour l'une toutes les informations par quartiers admnistratifs et la seconde comptient les positions des trotinnettes associées aux informations du quartier admnistratifs dans lesquelles elles se trouvent. Nous vous reccommandons de ne pas éxécuter certainespartie de ce code car cela met plusieurs heures pour s'éxécuter totalement. Nous fournoussis les fichiers créés à partir de l'éxécution de ces parties. La récolte des données des trotinnettes s'est faite sur 2 jours (Lundi et Samedi) et plusieurs heures : 9h 14h et 19h pour le Lundi et 9h, 14h, 16h, 18h et 19h. Le choix d'avoir chois plus d'heures le Lundi se justifie par le fait que c'est le week-end et que tous les commerces sont ouverts, ce qui nous laisse présupposer qu'il y a plus de mobilité ce jour-là. Ainsi, nous fournissons un exemple du code pour la journée de Samedi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/Users/dalilyoucefi/Documents/ProjetInfo/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import tempfile\n",
    "import zipfile\n",
    "import math\n",
    "import urllib.parse\n",
    "import numpy as np\n",
    "from urllib import request\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Récolte des données des trotinnettes (à ne pas éxécuter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## On récupère les données des trotinnettes sur l'API de Tier et on les met dans unre liste ppur créer le DataFrame\n",
    "r=requests.get(\"https://platform.tier-services.io/v2/vehicle?zoneId=PARIS\",headers={\"X-Api-Key\": \"bpEUTJEBTf74oGRWxaIcW7aeZMzDDODe1yBoSxi2\"})\n",
    "print(r.json()[\"data\"][1])\n",
    "df= pd.DataFrame(data=r.json()[\"data\"])\n",
    "BatteryLevel=[r.json()[\"data\"][i][\"attributes\"][\"batteryLevel\"] for i in range(len(r.json()[\"data\"]))]\n",
    "Lat=[r.json()[\"data\"][i][\"attributes\"][\"lat\"] for i in range(len(r.json()[\"data\"]))]\n",
    "Lng=[r.json()[\"data\"][i][\"attributes\"][\"lng\"] for i in range(len(r.json()[\"data\"]))]\n",
    "Type=[r.json()[\"data\"][i][\"attributes\"][\"vehicleType\"] for i in range(len(r.json()[\"data\"]))]\n",
    "Status=[r.json()[\"data\"][i][\"attributes\"][\"state\"] for i in range(len(r.json()[\"data\"]))]\n",
    "ID=[r.json()[\"data\"][i][\"id\"] for i in range(len(r.json()[\"data\"]))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On indique aussi l'heure et le jour où on a récupéré les données\n",
    "df_Tier=pd.DataFrame(columns=[\"ID\",\"BatteryLevel\",\"Lat\",\"Lng\",\"Type\",\"Status\"])\n",
    "df_Tier = df_Tier.fillna(0)\n",
    "df_Tier[\"ID\"]=ID\n",
    "df_Tier[\"BatteryLevel\"]=BatteryLevel\n",
    "df_Tier[\"Lat\"]=Lat\n",
    "df_Tier[\"Lng\"]=Lng\n",
    "df_Tier[\"Type\"]=Type\n",
    "df_Tier[\"Status\"]=Status\n",
    "df_Tier[\"Heure\"]=\"19h\"\n",
    "df_Tier[\"Jour\"]=\"Samedi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On sauvegarde la base de donnée\n",
    "df_Tier.to_csv(path+\"TierBase19HSa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On importe les données géographique des quartiers administratifs et des arrondissements de Paris trouvé sur le site OpenDataParis\n",
    "gdf = gpd.read_file(path+\"arrondissements.geojson').sort_values(by=\"c_ar\").reset_index()\n",
    "gdf2=gpd.read_file(path+ \"quartier_paris.geojson')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On transforme la base en GeoDataFrame\n",
    "df_Tier=pd.read_csv(path+\"TierBase19HSa.csv\")\n",
    "gdf_Tier = gpd.GeoDataFrame(df_Tier, geometry=gpd.points_from_xy(df_Tier.Lng, df_Tier.Lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On crée 2 fonctions qui permettent de déterminer dans quel quartier administratif et arrondissement se trouvent les trotinnettes \n",
    "\n",
    "def arrondissementappartenance(point):\n",
    "    for i in range(20):\n",
    "        if point.within(gdf[\"geometry\"][i]):\n",
    "            return int(i+1)\n",
    "\n",
    "\n",
    "def quartierappartenance(point):\n",
    "    for i in range(80):\n",
    "        if point.within(gdf2[\"geometry\"][i]):\n",
    "            return gdf2[\"c_qu\"][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On fusionne les bases sur les données récoltées dans la journée (fichiers pour les autres heures et jour fournis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gdf_Tier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-18332b946070>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#On sauvegarde\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgdf_Tier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Arrondissement\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mgdf_Tier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"geometry\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrondissementappartenance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgdf_Tier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id_quartier\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgdf_Tier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"geometry\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquartierappartenance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgdf_Tier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gdf_Tier' is not defined"
     ]
    }
   ],
   "source": [
    "#On sauvegarde \n",
    "gdf_Tier[\"Arrondissement\"]= gdf_Tier[\"geometry\"].apply(arrondissementappartenance)\n",
    "gdf_Tier[\"id_quartier\"]=gdf_Tier[\"geometry\"].apply(quartierappartenance)\n",
    "gdf_Tier.head()\n",
    "\n",
    "gdf_Tier.to_file(path+\"GeoTier19HSa.geojson\", driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(path+\"GeoTier9HSa.geojson\")\n",
    "gdf2=gpd.read_file(path+\"GeoTier14HSa.geojson\")\n",
    "gdf3=gpd.read_file(path+\"GeoTier16HSa.geojson\")\n",
    "gdf4=gpd.read_file(path+\"GeoTier18HSa.geojson\")\n",
    "gdf5=gpd.read_file(path+\"GeoTier19HSa.geojson\")\n",
    "gdf6=gdf.append(gdf2,ignore_index=True)\n",
    "gdf6=gdf6.append(gdf3,ignore_index=True)\n",
    "gdf6=gdf6.append(gdf4,ignore_index=True)\n",
    "gdf6=gdf6.append(gdf5,ignore_index=True)\n",
    "\n",
    "gdf6.to_file(path+\"GeoTierSa.geojson\", driver='GeoJSON')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Récupération des positions des stations de métro, RER et Tramway et calcul de la distance de la station la plus proche à chaque trotinnette "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gares_id</th>\n",
       "      <th>nomlong</th>\n",
       "      <th>mode</th>\n",
       "      <th>ligne</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93</td>\n",
       "      <td>BOTZARIS</td>\n",
       "      <td>Metro</td>\n",
       "      <td>7b</td>\n",
       "      <td>POINT (2.38912 48.87948)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>ASSEMBLEE NATIONALE</td>\n",
       "      <td>Metro</td>\n",
       "      <td>12</td>\n",
       "      <td>POINT (2.32100 48.86079)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>BALARD</td>\n",
       "      <td>Metro</td>\n",
       "      <td>8</td>\n",
       "      <td>POINT (2.27816 48.83593)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>BASTILLE</td>\n",
       "      <td>Metro</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (2.36932 48.85248)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>BEL-AIR</td>\n",
       "      <td>Metro</td>\n",
       "      <td>6</td>\n",
       "      <td>POINT (2.40092 48.84134)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gares_id              nomlong   mode ligne                  geometry\n",
       "0        93             BOTZARIS  Metro    7b  POINT (2.38912 48.87948)\n",
       "1        30  ASSEMBLEE NATIONALE  Metro    12  POINT (2.32100 48.86079)\n",
       "2        47               BALARD  Metro     8  POINT (2.27816 48.83593)\n",
       "3        54             BASTILLE  Metro     1  POINT (2.36932 48.85248)\n",
       "4        59              BEL-AIR  Metro     6  POINT (2.40092 48.84134)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On récupère les informations des stations de métro, RER et Tramway de Paris sur le site d'ile de ffrance mobilité\n",
    "stations = open(path+\"emplacement-des-gares-idf.geojson\", \"r\")\n",
    "stations = gpd.read_file(stations)\n",
    "stations= stations[[\"gares_id\",\"nomlong\",\"mode\",\"ligne\",\"geometry\"]]\n",
    "stations.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comme les coordonnées sont en latitudes et longitudes, on ne peut pas calculer de distance, donc nous allons devoir créer une fonction pour la calculer\n",
    "\n",
    "df1 = gpd.read_file(path+\"GeoTierSa.geojson\")\n",
    "df1[\"x\"]=df1[\"geometry\"].x\n",
    "df1[\"y\"]=df1[\"geometry\"].y\n",
    "stations[\"x\"]=stations[\"geometry\"].x\n",
    "stations[\"y\"]=stations[\"geometry\"].y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(x1,y1,x2,y2):\n",
    "    R = 6373.0\n",
    "    \n",
    "    \n",
    "    lat1 = math.radians(y1)\n",
    "\n",
    "    lon1 = math.radians(x1)\n",
    "    lat2 = math.radians(y2)\n",
    "    lon2 = math.radians(x2)\n",
    "    \n",
    "    dlon = lon2 - lon1\n",
    "    \n",
    "    dlat = lat2 - lat1\n",
    "    \n",
    "    a = math.sin(dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    distance = R * c\n",
    "    return (distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On retrouve ainsi la station de métro la plus proche et toutes ses informations\n",
    "min_distancei = float(1000000)\n",
    "min_distance = []\n",
    "station_min = []\n",
    "ligne_min=[]\n",
    "\n",
    "for i in range(len(df1)):\n",
    "    min_distancei = float(100000)\n",
    "    station_min0 = \"Essai\"\n",
    "    ligne_min0=\"Essai\"\n",
    "    \n",
    "    for j in range(len(stations)):\n",
    "        \n",
    "        if distance(df1[\"x\"][i],df1[\"y\"][i],stations[\"x\"][j],stations[\"y\"][j]) <= min_distancei :\n",
    "                min_distancei = distance(df1[\"x\"][i],df1[\"y\"][i],stations[\"x\"][j],stations[\"y\"][j])\n",
    "                station_min0 = stations['nomlong'][j]\n",
    "                ligne_min0=stations[\"ligne\"][j]\n",
    "                \n",
    "           \n",
    "\n",
    "    min_distance.append(min_distancei)\n",
    "    station_min.append(station_min0)\n",
    "    ligne_min.append(ligne_min0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On ajoute ça au GeoDataFrame\n",
    "df1[\"station_min\"] = station_min\n",
    "df1[\"min_distance\"] = min_distance\n",
    "df1[\"ligne_min\"]=ligne_min\n",
    "\n",
    "df1.head()\n",
    "\n",
    "df1.to_file(path+\"TierMetroSa.geojson\", driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Données démographique par quartiers admnistratifs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0df6d27c3992>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0marr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0murl_req\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"https://www.insee.fr/fr/statistiques/2011101?geo=COM-751\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mrequest_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbs4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lxml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtableau_participants\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'table'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'id'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m\"produit-tableau-POP_T0\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 543\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0;32m-> 1362\u001b[0;31m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[1;32m   1363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m             \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1342\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1345\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Nous allons récupérer sur le site de l'INSEE les données démographiques des arrondissements par tranche d'âge\n",
    "liste_ageprop=[]\n",
    "liste_ageabs=[]\n",
    "for j in range(1,21):\n",
    "    if j<10:\n",
    "        arr=\"0\"+str(j)\n",
    "    else:\n",
    "        arr=str(j)\n",
    "    url_req=\"https://www.insee.fr/fr/statistiques/2011101?geo=COM-751\"+arr\n",
    "    request_text = request.urlopen(url_req).read()\n",
    "    page = bs4.BeautifulSoup(request_text, \"lxml\")\n",
    "    tableau_participants = page.find('table', {'id' : \"produit-tableau-POP_T0\"})\n",
    "    table_body = tableau_participants.find('tbody')\n",
    "    rows = table_body.find_all('tr')\n",
    "    li1=[]\n",
    "    li2=[]\n",
    "    for i in range(len(rows)):\n",
    "        if i>=2:\n",
    "           \n",
    "            cols = rows[i].find_all('td')\n",
    "            cols = [ele.text.strip() for ele in cols]\n",
    "            li1.append(cols[-1])\n",
    "            li2.append(cols[-2])\n",
    "    liste_ageprop.append(li1)\n",
    "    liste_ageabs.append(li2)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    " #On va rajouter ces données dans la Dataframe des arrondissements     \n",
    "gdf = gpd.read_file(path+\"arrondissements.geojson\").sort_values(by=\"c_ar\").reset_index()\n",
    "\n",
    "liste2=np.array(liste_ageprop)\n",
    "gdf[\"prop_0-14\"]=liste2[:,0].tolist()\n",
    "gdf[\"prop_15-29\"]=liste2[:,1].tolist()\n",
    "gdf[\"prop_30-44\"]=liste2[:,2].tolist()\n",
    "gdf[\"prop_45-59\"]=liste2[:,3].tolist()\n",
    "gdf[\"prop_60-74\"]=liste2[:,4].tolist()\n",
    "gdf[\"prop_75+\"]=liste2[:,5].tolist()\n",
    "\n",
    "liste3=np.array(liste_ageabs)\n",
    "gdf[\"nombre_0-14\"]=liste3[:,0].tolist()\n",
    "gdf[\"nombre_15-29\"]=liste3[:,1].tolist()\n",
    "gdf[\"nombre_30-44\"]=liste3[:,2].tolist()\n",
    "gdf[\"nombre_45-59\"]=liste3[:,3].tolist()\n",
    "gdf[\"nombre_60-74\"]=liste3[:,4].tolist()\n",
    "gdf[\"nombre_75+\"]=liste3[:,5].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dalilyoucefi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/dalilyoucefi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/Users/dalilyoucefi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/dalilyoucefi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/Users/dalilyoucefi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/dalilyoucefi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/dalilyoucefi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/dalilyoucefi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/dalilyoucefi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/Users/dalilyoucefi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/Users/dalilyoucefi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/dalilyoucefi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/dalilyoucefi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/Users/dalilyoucefi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/dalilyoucefi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/dalilyoucefi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/dalilyoucefi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/dalilyoucefi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/dalilyoucefi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/dalilyoucefi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/dalilyoucefi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/dalilyoucefi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/dalilyoucefi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/dalilyoucefi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#On supprime les caractères en trop pouvoir convertir les données en flottant\n",
    "for i in range(len(gdf)):\n",
    "\n",
    "    gdf[\"prop_0-14\"][i]=gdf[\"prop_0-14\"][i].replace('\\xa0','')\n",
    "    gdf[\"prop_15-29\"][i]=gdf[\"prop_15-29\"][i].replace('\\xa0','')\n",
    "    gdf[\"prop_30-44\"][i]=gdf[\"prop_30-44\"][i].replace('\\xa0','')\n",
    "    gdf[\"prop_45-59\"][i]=gdf[\"prop_45-59\"][i].replace('\\xa0','')\n",
    "    gdf[\"prop_60-74\"][i]=gdf[\"prop_60-74\"][i].replace('\\xa0','')\n",
    "    gdf[\"prop_75+\"][i]=gdf[\"prop_75+\"][i].replace('\\xa0','')\n",
    "    gdf[\"nombre_0-14\"][i]=gdf[\"nombre_0-14\"][i].replace('\\xa0','')\n",
    "    gdf[\"nombre_15-29\"][i]=gdf[\"nombre_15-29\"][i].replace('\\xa0','')\n",
    "    gdf[\"nombre_30-44\"][i]=gdf[\"nombre_30-44\"][i].replace('\\xa0','')\n",
    "    gdf[\"nombre_45-59\"][i]=gdf[\"nombre_45-59\"][i].replace('\\xa0','')\n",
    "    gdf[\"nombre_60-74\"][i]=gdf[\"nombre_60-74\"][i].replace('\\xa0','')\n",
    "    gdf[\"nombre_75+\"][i]=gdf[\"nombre_75+\"][i].replace('\\xa0','')\n",
    "    gdf[\"prop_0-14\"][i]=gdf[\"prop_0-14\"][i].replace(',','.')\n",
    "    gdf[\"prop_15-29\"][i]=gdf[\"prop_15-29\"][i].replace(',','.')\n",
    "    gdf[\"prop_30-44\"][i]=gdf[\"prop_30-44\"][i].replace(',','.')\n",
    "    gdf[\"prop_45-59\"][i]=gdf[\"prop_45-59\"][i].replace(',','.')\n",
    "    gdf[\"prop_60-74\"][i]=gdf[\"prop_60-74\"][i].replace(',','.')\n",
    "    gdf[\"prop_75+\"][i]=gdf[\"prop_75+\"][i].replace(',','.')\n",
    "    gdf[\"nombre_0-14\"][i]=gdf[\"nombre_0-14\"][i].replace(',','.')\n",
    "    gdf[\"nombre_15-29\"][i]=gdf[\"nombre_15-29\"][i].replace(',','.')\n",
    "    gdf[\"nombre_30-44\"][i]=gdf[\"nombre_30-44\"][i].replace(',','.')\n",
    "    gdf[\"nombre_45-59\"][i]=gdf[\"nombre_45-59\"][i].replace(',','.')\n",
    "    gdf[\"nombre_60-74\"][i]=gdf[\"nombre_60-74\"][i].replace(',','.')\n",
    "    gdf[\"nombre_75+\"][i]=gdf[\"nombre_75+\"][i].replace(',','.')\n",
    "gdf[\"prop_0-14\"]=(gdf[\"prop_0-14\"]).astype(float)\n",
    "gdf[\"prop_15-29\"]=gdf[\"prop_15-29\"].astype(float)\n",
    "gdf[\"prop_30-44\"]=gdf[\"prop_30-44\"].astype(float)\n",
    "gdf[\"prop_45-59\"]=gdf[\"prop_45-59\"].astype(float)\n",
    "gdf[\"prop_60-74\"]=gdf[\"prop_60-74\"].astype(float)\n",
    "gdf[\"prop_75+\"]=gdf[\"prop_75+\"].astype(float)\n",
    "gdf[\"nombre_0-14\"]=gdf[\"nombre_0-14\"].astype(float)\n",
    "gdf[\"nombre_15-29\"]=gdf[\"nombre_15-29\"].astype(float)\n",
    "gdf[\"nombre_30-44\"]=gdf[\"nombre_30-44\"].astype(float)\n",
    "gdf[\"nombre_45-59\"]=gdf[\"nombre_45-59\"].astype(float)\n",
    "gdf[\"nombre_60-74\"]=gdf[\"nombre_60-74\"].astype(float)\n",
    "gdf[\"nombre_75+\"]=gdf[\"nombre_75+\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On va rajouter la population totale et ne garder que les informations essentielles\n",
    "gdf[\"pop\"]=gdf[\"nombre_0-14\"]+gdf[\"nombre_15-29\"]+gdf[\"nombre_30-44\"]+gdf[\"nombre_45-59\"]+gdf[\"nombre_60-74\"]+gdf[\"nombre_75+\"]\n",
    "li=[9863,21872,29638,17838,24817,21062,13936,10147,26888,323888,41341,8686,24896,23684,27201,9714,29166,31701,27274,32494]\n",
    "gdf[\"densite\"]=li\n",
    "gdf2=gdf[[\"l_ar\",\"c_ar\",\"prop_0-14\",\"prop_15-29\",'prop_30-44', 'prop_45-59', 'prop_60-74', 'prop_75+', 'nombre_0-14',\n",
    "       'nombre_15-29', 'nombre_30-44', 'nombre_45-59', 'nombre_60-74',\n",
    "       'nombre_75+', 'pop', 'densite']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On fusionne la base avec celle des quartiers administratifs\n",
    "gdf_quart=gpd.read_file(path+\"quartier_paris.geojson\")\n",
    "gdf3=gdf_quart.merge(gdf2, left_on=\"c_ar\",right_on=\"c_ar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On va aussi rajouter les données du nombre de transports en commun dans les quartiers administratifs\n",
    "stations = open(path+\"emplacement-des-gares-idf.geojson\", \"r\")\n",
    "stations = gpd.read_file(stations)\n",
    "stations= stations[[\"gares_id\",\"nomlong\",\"mode\",\"ligne\",\"geometry\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nombrestation(x):\n",
    "    li=[0 for i in range(80)]\n",
    "    for j in range(len(x)):\n",
    "        \n",
    "        for i in range(80):\n",
    "            if x[\"geometry\"][j].within(gdf3[\"geometry\"][i]):\n",
    "                li[i]+=1\n",
    "    return (li)\n",
    "\n",
    "gdf3[\"nombretransport\"]=nombrestation(stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_sq_qu</th>\n",
       "      <th>n_sq_ar</th>\n",
       "      <th>c_qu</th>\n",
       "      <th>surface</th>\n",
       "      <th>l_qu</th>\n",
       "      <th>perimetre</th>\n",
       "      <th>c_quinsee</th>\n",
       "      <th>c_ar</th>\n",
       "      <th>geometry</th>\n",
       "      <th>l_ar</th>\n",
       "      <th>...</th>\n",
       "      <th>prop_75+</th>\n",
       "      <th>nombre_0-14</th>\n",
       "      <th>nombre_15-29</th>\n",
       "      <th>nombre_30-44</th>\n",
       "      <th>nombre_45-59</th>\n",
       "      <th>nombre_60-74</th>\n",
       "      <th>nombre_75+</th>\n",
       "      <th>pop</th>\n",
       "      <th>densite</th>\n",
       "      <th>nombretransport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>750000020</td>\n",
       "      <td>750000005</td>\n",
       "      <td>20</td>\n",
       "      <td>433197.792441</td>\n",
       "      <td>Sorbonne</td>\n",
       "      <td>2892.944068</td>\n",
       "      <td>7510504</td>\n",
       "      <td>5</td>\n",
       "      <td>POLYGON ((2.34924 48.84452, 2.34888 48.84449, ...</td>\n",
       "      <td>5ème Ardt</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6735.0</td>\n",
       "      <td>17195.0</td>\n",
       "      <td>10190.0</td>\n",
       "      <td>9966.0</td>\n",
       "      <td>9148.0</td>\n",
       "      <td>5615.0</td>\n",
       "      <td>58849.0</td>\n",
       "      <td>24817</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>750000019</td>\n",
       "      <td>750000005</td>\n",
       "      <td>19</td>\n",
       "      <td>703631.162923</td>\n",
       "      <td>Val-de-Grâce</td>\n",
       "      <td>3485.831358</td>\n",
       "      <td>7510503</td>\n",
       "      <td>5</td>\n",
       "      <td>POLYGON ((2.34548 48.84507, 2.34661 48.84480, ...</td>\n",
       "      <td>5ème Ardt</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6735.0</td>\n",
       "      <td>17195.0</td>\n",
       "      <td>10190.0</td>\n",
       "      <td>9966.0</td>\n",
       "      <td>9148.0</td>\n",
       "      <td>5615.0</td>\n",
       "      <td>58849.0</td>\n",
       "      <td>24817</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>750000017</td>\n",
       "      <td>750000005</td>\n",
       "      <td>17</td>\n",
       "      <td>604156.072897</td>\n",
       "      <td>Saint-Victor</td>\n",
       "      <td>3087.215040</td>\n",
       "      <td>7510501</td>\n",
       "      <td>5</td>\n",
       "      <td>POLYGON ((2.35492 48.84378, 2.35492 48.84364, ...</td>\n",
       "      <td>5ème Ardt</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6735.0</td>\n",
       "      <td>17195.0</td>\n",
       "      <td>10190.0</td>\n",
       "      <td>9966.0</td>\n",
       "      <td>9148.0</td>\n",
       "      <td>5615.0</td>\n",
       "      <td>58849.0</td>\n",
       "      <td>24817</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>750000018</td>\n",
       "      <td>750000005</td>\n",
       "      <td>18</td>\n",
       "      <td>798389.398463</td>\n",
       "      <td>Jardin-des-Plantes</td>\n",
       "      <td>4052.729521</td>\n",
       "      <td>7510502</td>\n",
       "      <td>5</td>\n",
       "      <td>POLYGON ((2.36456 48.84366, 2.36450 48.84358, ...</td>\n",
       "      <td>5ème Ardt</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6735.0</td>\n",
       "      <td>17195.0</td>\n",
       "      <td>10190.0</td>\n",
       "      <td>9966.0</td>\n",
       "      <td>9148.0</td>\n",
       "      <td>5615.0</td>\n",
       "      <td>58849.0</td>\n",
       "      <td>24817</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>750000033</td>\n",
       "      <td>750000009</td>\n",
       "      <td>33</td>\n",
       "      <td>717091.569643</td>\n",
       "      <td>Saint-Georges</td>\n",
       "      <td>3429.188334</td>\n",
       "      <td>7510901</td>\n",
       "      <td>9</td>\n",
       "      <td>POLYGON ((2.33923 48.87679, 2.33816 48.87686, ...</td>\n",
       "      <td>9ème Ardt</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8367.0</td>\n",
       "      <td>14887.0</td>\n",
       "      <td>15117.0</td>\n",
       "      <td>10598.0</td>\n",
       "      <td>7031.0</td>\n",
       "      <td>3556.0</td>\n",
       "      <td>59556.0</td>\n",
       "      <td>26888</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     n_sq_qu    n_sq_ar  c_qu        surface                l_qu    perimetre  \\\n",
       "0  750000020  750000005    20  433197.792441            Sorbonne  2892.944068   \n",
       "1  750000019  750000005    19  703631.162923        Val-de-Grâce  3485.831358   \n",
       "2  750000017  750000005    17  604156.072897        Saint-Victor  3087.215040   \n",
       "3  750000018  750000005    18  798389.398463  Jardin-des-Plantes  4052.729521   \n",
       "4  750000033  750000009    33  717091.569643       Saint-Georges  3429.188334   \n",
       "\n",
       "   c_quinsee  c_ar                                           geometry  \\\n",
       "0    7510504     5  POLYGON ((2.34924 48.84452, 2.34888 48.84449, ...   \n",
       "1    7510503     5  POLYGON ((2.34548 48.84507, 2.34661 48.84480, ...   \n",
       "2    7510501     5  POLYGON ((2.35492 48.84378, 2.35492 48.84364, ...   \n",
       "3    7510502     5  POLYGON ((2.36456 48.84366, 2.36450 48.84358, ...   \n",
       "4    7510901     9  POLYGON ((2.33923 48.87679, 2.33816 48.87686, ...   \n",
       "\n",
       "        l_ar  ...  prop_75+  nombre_0-14  nombre_15-29  nombre_30-44  \\\n",
       "0  5ème Ardt  ...       9.5       6735.0       17195.0       10190.0   \n",
       "1  5ème Ardt  ...       9.5       6735.0       17195.0       10190.0   \n",
       "2  5ème Ardt  ...       9.5       6735.0       17195.0       10190.0   \n",
       "3  5ème Ardt  ...       9.5       6735.0       17195.0       10190.0   \n",
       "4  9ème Ardt  ...       6.0       8367.0       14887.0       15117.0   \n",
       "\n",
       "   nombre_45-59  nombre_60-74  nombre_75+      pop  densite  nombretransport  \n",
       "0        9966.0        9148.0      5615.0  58849.0    24817                4  \n",
       "1        9966.0        9148.0      5615.0  58849.0    24817                1  \n",
       "2        9966.0        9148.0      5615.0  58849.0    24817                3  \n",
       "3        9966.0        9148.0      5615.0  58849.0    24817                2  \n",
       "4       10598.0        7031.0      3556.0  59556.0    26888                4  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On sauvegarde\n",
    "\n",
    "gdf3.to_file(path+\"BaseQuartier.geojson\",driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Logements sociaux et commerces à Paris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importation des données des logements sociaux à Paris\n",
    "gdf_logements_soc = gpd.read_file(path+\"logements-sociaux-finances-a-paris.geojson\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#suppression de variables\n",
    "gdf_logements_soc.drop(['nature_programme','arrdt','ville','n_livraison','adresse_programme','code_postal','annee','bs','nb_plai','nb_plus','nb_pluscd','nb_pls','mode_real','commentaires','coord_x_l93','coord_y_l93'], 1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on importe les données\n",
    "file_name='quartier_paris.geojson'\n",
    "file = open(file_name)\n",
    "gdf = gpd.read_file(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_logmt_total</th>\n",
       "      <th>geometry</th>\n",
       "      <th>quartier</th>\n",
       "      <th>numquartier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>POINT (2.35610 48.88885)</td>\n",
       "      <td>Goutte-d'Or</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>POINT (2.35272 48.89786)</td>\n",
       "      <td>Goutte-d'Or</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>POINT (2.28424 48.85746)</td>\n",
       "      <td>Muette</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>POINT (2.30706 48.83217)</td>\n",
       "      <td>Saint-Lambert</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>POINT (2.33014 48.88459)</td>\n",
       "      <td>Grandes-Carrières</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3579</th>\n",
       "      <td>8</td>\n",
       "      <td>POINT (2.35167 48.88680)</td>\n",
       "      <td>Goutte-d'Or</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3580</th>\n",
       "      <td>11</td>\n",
       "      <td>POINT (2.35457 48.85843)</td>\n",
       "      <td>Saint-Merri</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3581</th>\n",
       "      <td>26</td>\n",
       "      <td>POINT (2.37470 48.86153)</td>\n",
       "      <td>Saint-Ambroise</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3582</th>\n",
       "      <td>22</td>\n",
       "      <td>POINT (2.35424 48.85889)</td>\n",
       "      <td>Saint-Merri</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3583</th>\n",
       "      <td>6</td>\n",
       "      <td>POINT (2.37629 48.85297)</td>\n",
       "      <td>Sainte-Marguerite</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3584 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      nb_logmt_total                  geometry           quartier  numquartier\n",
       "0                 12  POINT (2.35610 48.88885)        Goutte-d'Or           71\n",
       "1                 22  POINT (2.35272 48.89786)        Goutte-d'Or           71\n",
       "2                 37  POINT (2.28424 48.85746)             Muette           62\n",
       "3                 16  POINT (2.30706 48.83217)      Saint-Lambert           57\n",
       "4                 14  POINT (2.33014 48.88459)  Grandes-Carrières           69\n",
       "...              ...                       ...                ...          ...\n",
       "3579               8  POINT (2.35167 48.88680)        Goutte-d'Or           71\n",
       "3580              11  POINT (2.35457 48.85843)        Saint-Merri           13\n",
       "3581              26  POINT (2.37470 48.86153)     Saint-Ambroise           42\n",
       "3582              22  POINT (2.35424 48.85889)        Saint-Merri           13\n",
       "3583               6  POINT (2.37629 48.85297)  Sainte-Marguerite           44\n",
       "\n",
       "[3584 rows x 4 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def quartierappartenance(point):\n",
    "    for i in range(80):\n",
    "        if point.within(gdf[\"geometry\"][i]):\n",
    "            return gdf[\"l_qu\"][i]\n",
    "\n",
    "def numquartierappartenance(point):\n",
    "    for i in range(80):\n",
    "        if point.within(gdf[\"geometry\"][i]):\n",
    "            return gdf[\"c_qu\"][i]\n",
    "gdf_logements_soc[\"quartier\"]=gdf_logements_soc[\"geometry\"].apply(quartierappartenance)\n",
    "gdf_logements_soc[\"numquartier\"]=gdf_logements_soc[\"geometry\"].apply(numquartierappartenance)\n",
    "gdf_logements_soc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['numquartier', 'nb_logmt_total'], dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on va indiquer le nombre de logement qu'on a par quartier administratif\n",
    "\n",
    "gdf_logements_sociaux = gdf_logements_soc.groupby(['numquartier'],as_index=False).sum()\n",
    "gdf_logements_sociaux.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on importe les données\n",
    "gdf_l = gpd.read_file(path+\"logement-encadrement-des-loyers.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppression de variables\n",
    "gdf_l.drop(['ville','epoque','meuble_txt','code_grand_quartier','piece','max','min','id_zone','annee'],1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on va calculer la moyenne des loyers dans chaque quartier administratif\n",
    "gdf_loyer=gdf_l.groupby(['id_quartier'],as_index=False).mean()\n",
    "g1 = gdf_loyer.rename(columns={'id_quartier':'numquartier'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on importe les données sur les commerces parisiens\n",
    "file_name=path+ 'coronavirus-commercants-parisiens-livraison-a-domicile.geojson'\n",
    "file = open(file_name)\n",
    "gdf_co = gpd.read_file(file)\n",
    "\n",
    "gdf_co['quartier']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on va indiquer à quel quartier administratif appartient le commerce \n",
    "gdf_co[\"quartier\"]=gdf_co[\"geometry\"].apply(quartierappartenance)\n",
    "gdf_co['numquartier']=gdf_co['geometry'].apply(numquartierappartenance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on va supprimer des variables \n",
    "gdf_co.drop(['code_postal','description','nom_du_commerce','adresse','telephone','services','mail','type_de_commerce','site_internet','precisions'],1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# on va créer une variable qui va indiquer le nombre total de commerce par quartier administratif\n",
    "gdf_co['nombre_de_commerce']=1\n",
    "gdf_commerce=gdf_co.groupby('numquartier',as_index=False).sum()\n",
    "gdf_commerce\n",
    "\n",
    "df1=pd.merge(g1,gdf_logements_sociaux,on=\"numquartier\")\n",
    "\n",
    "df_final = pd.merge(df1,gdf_commerce,on=\"numquartier\")\n",
    "\n",
    "df_final.to_csv(path+\"bdd_quart.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Données des entreprises  (à ne pas éxécuter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On récolte les données des entreprises à partir de la base du site DatainfoGreffe\n",
    "\n",
    "ent=pd.read_csv(\"/Users/dalilyoucefi/Downloads/entreprise.csv\", sep=\",\")\n",
    "ent[\"Code postal\"]=ent[\"Code postal\"].astype(str)\n",
    "ent[\"fulladress\"]=ent[\"Adresse\"]+\", \"+ent[\"Code postal\"]+ \" \"+ent[\"Ville\"]\n",
    "ent=ent.dropna().reset_index()\n",
    "#On supprime cette ligne car elle pose un problème pour plus tard\n",
    "ent=ent.drop([13522]).reset_index()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On va à partir de l'adresse récupérer les coordonnées \n",
    "\n",
    "def positionlon(adr):\n",
    "\n",
    "    headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 6.0; WOW64; rv:24.0) Gecko/20100101 Firefox/24.0' }\n",
    "    api_url = \"https://api-adresse.data.gouv.fr/search/?q=\"\n",
    "\n",
    "    r = requests.get(api_url + urllib.parse.quote(adr),headers=headers)\n",
    "\n",
    "\n",
    "    \n",
    "    return(r.json()[\"features\"][0][\"geometry\"][\"coordinates\"][0])\n",
    "\n",
    "li=[]\n",
    "i=0\n",
    "for j in range(len(ent)):\n",
    "    i+=1\n",
    "    li.append(positionlon(ent[\"fulladress\"][j]))\n",
    "    print(i)\n",
    "\n",
    "ent[\"lon\"]=li\n",
    "ent.to_csv(path+\"entrepriselon.csv\")\n",
    "ent3=pd.read_csv(path+\"entrepriselon.csv\")\n",
    "\n",
    "\n",
    "def positionla(adr):\n",
    "\n",
    "    headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 6.0; WOW64; rv:24.0) Gecko/20100101 Firefox/24.0' }\n",
    "    api_url = \"https://api-adresse.data.gouv.fr/search/?q=\"\n",
    "\n",
    "    r = requests.get(api_url + urllib.parse.quote(adr),headers=headers)\n",
    "\n",
    "\n",
    "    \n",
    "    return(r.json()[\"features\"][0][\"geometry\"][\"coordinates\"][1])\n",
    "\n",
    "li1=[]\n",
    "i=0\n",
    "for j in range(len(ent3)):\n",
    "    i+=1\n",
    "    li1.append(positionla(ent3[\"fulladress\"][j]))\n",
    "    print(i)\n",
    "ent3[\"la\"]=li1\n",
    "\n",
    "#On garde ces données car elles mettent beaucoup de temps à être récoltée\n",
    "ent3.to_csv(path+\"entrepriselonlat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On convertit en DataFrame\n",
    "geoent = gpd.GeoDataFrame(ent3, geometry=gpd.points_from_xy(ent3.lon, ent3.la))\n",
    "gdf2=gpd.read_file(path+\"quartier_paris.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On détermine dans quel quartier se trouve chaque entreprise\n",
    "def quartierappartenance(point):\n",
    "    for i in range(80):\n",
    "        print(i)\n",
    "        if point.within(gdf2[\"geometry\"][i]):\n",
    "            return gdf2[\"l_qu\"][i]\n",
    "def quartierappartenance2(point):\n",
    "    for i in range(80):\n",
    "        print(i)\n",
    "        if point.within(gdf2[\"geometry\"][i]):\n",
    "            return gdf2[\"c_qu\"][i]\n",
    "        \n",
    "geoent[\"nomquartier\"]=geoent[\"geometry\"].apply(quartierappartenance)\n",
    "geoent[\"id_quartier\"]=geoent[\"geometry\"].apply(quartierappartenance2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On fait un groupby pour calculer la moyenne de chiffre d'affaire et par quartier\n",
    "geoent['nombreent']=1\n",
    "ent1=geoent.groupby('id_quartier',as_index=False).sum()\n",
    "ent1=ent1[[\"id_quartier\",\"nombreent\"]]\n",
    "\n",
    "ent2=geoent.groupby('id_quartier',as_index=False).mean()\n",
    "ent2=ent2[[\"id_quartier\",\"CA 1\"]]\n",
    "df1=pd.merge(ent1,ent2,on=\"id_quartier\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On sauvegarde\n",
    "df1.to_csv(path+\"entreprisefinal.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Fusion de toutes les bases pour en avoir 2 (Pour Samedi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['n_sq_qu', 'n_sq_ar', 'c_qu', 'surface', 'l_qu', 'perimetre',\n",
       "       'c_quinsee', 'c_ar', 'l_ar', 'prop_0-14', 'prop_15-29', 'prop_30-44',\n",
       "       'prop_45-59', 'prop_60-74', 'prop_75+', 'nombre_0-14', 'nombre_15-29',\n",
       "       'nombre_30-44', 'nombre_45-59', 'nombre_60-74', 'nombre_75+', 'pop',\n",
       "       'densite', 'nombretransport', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On charge toutes les bases sauvegardées pour les fusionner afin d'avoir seulement 2 bases de travail\n",
    "gdf_quart1= gpd.read_file(path+\"BaseQuartier.csv\")[[\"c_qu\",\"l_qu\",\"c_ar\",\"l_ar\", 'prop_0-14', 'prop_15-29', 'prop_30-44',\n",
    "       'prop_45-59', 'prop_60-74', 'prop_75+', 'nombre_0-14', 'nombre_15-29',\n",
    "       'nombre_30-44', 'nombre_45-59', 'nombre_60-74', 'nombre_75+', 'pop', 'densite', 'nombretransport']]\n",
    "gdf_quart2= gpd.read_file(path+\"bdd_quart.csv\")\n",
    "gdf_ent=gpd.read_file(path+\"entreprisefinal.csv\")\n",
    "gdf_Tier=gpd.read_file(path+\"TierMetroSa.geojson\").dropna()\n",
    "gdf_quart1[\"c_qu\"]=gdf_quart1[\"c_qu\"].astype(str)\n",
    "gdf_Tier[\"id_quartier\"]=gdf_Tier[\"id_quartier\"].astype(int)\n",
    "gdf_Tier[\"id_quartier\"]=gdf_Tier[\"id_quartier\"].astype(str)\n",
    "gdf_ent[\"id_quartier\"]=gdf_ent[\"id_quartier\"].astype(float)\n",
    "gdf_ent[\"id_quartier\"]=gdf_ent[\"id_quartier\"].astype(int)\n",
    "gdf_ent[\"id_quartier\"]=gdf_ent[\"id_quartier\"].astype(str)\n",
    "gdf_ent=gdf_ent[[\"id_quartier\",\"nombreent\",\"CA 1\"]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On fusionne toutes les données sur les quartiers\n",
    "gdf2=gdf_quart1.merge(gdf_quart2, left_on=\"c_qu\",right_on=\"numquartier\")\n",
    "gdf2=gdf2[['c_qu', 'l_qu', 'c_ar', 'l_ar', \"prop_0-14\",\"prop_15-29\",'prop_30-44', 'prop_45-59',\n",
    "       'prop_60-74', 'prop_75+', 'nombre_0-14', 'nombre_15-29', 'nombre_30-44',\n",
    "       'nombre_45-59', 'nombre_60-74', 'nombre_75+', 'pop', 'densite',\n",
    "       'nombretransport', 'field_1', 'numquartier', 'ref', 'nb_logmt_total',\n",
    "       'nombre_de_commerce']]\n",
    "gdf3=gdf2.merge(gdf_ent, left_on=\"c_qu\",right_on=\"id_quartier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On rajoute les données des quartiers sur toutes les trotinnettes pour rendre le traitement plus simple\n",
    "gdf_Tierfin=gdf_Tier.merge(gdf3, left_on=\"id_quartier\",right_on=\"c_qu\")\n",
    "gdf_Tierfin=gdf_Tierfin[[ 'ID', 'BatteryLevel', 'Lat', 'Lng', 'Type', 'Status',\n",
    "       'Heure', 'Jour', 'Arrondissement', 'densité', 'nomquartier', 'id_quartier_x', 'station_min', 'min_distance', 'ligne_min', \n",
    "       'geometry', 'c_qu', 'l_qu', 'c_ar', 'l_ar',\"prop_0-14\",\"prop_15-29\", 'prop_30-44', 'prop_45-59',\n",
    "       'prop_60-74', 'prop_75+', 'nombre_0-14', 'nombre_15-29', 'nombre_30-44',\n",
    "       'nombre_45-59', 'nombre_60-74', 'nombre_75+', 'pop', 'densite',\n",
    "       'nombretransport', 'field_1', 'numquartier', 'ref', 'nb_logmt_total',\n",
    "       'nombre_de_commerce']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gdf_Tierfin.rename(columns={\"id_quartier_x\":\"id_quartier\"},inplace=True)\n",
    "\n",
    "#On sauvegarde cette base\n",
    "gdf_Tierfin.to_file(path+\"Tierbasefin1geoSa.geojson\", driver='GeoJSON')\n",
    "#On va compter cette le nombre de trotinnette présente en fonction de chaque heure dans chaque quartier\n",
    "gdf_Tier['nombrtrot']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trot9=gdf_Tier[gdf_Tier[\"Heure\"]==\"9h\"].groupby('id_quartier',as_index=False).sum()\n",
    "trot9=trot9[[\"id_quartier\",\"nombrtrot\"]]\n",
    "\n",
    "#  il y avait un quartier où aucune trotinette était présente, il faut donc rajouter une ligne  pour indiquer qu'il n'y en a pas\n",
    "\n",
    "data=[(\"16\",0)]\n",
    "index=[\"1\"]\n",
    "columns=[\"id_quartier\",\"nombrtrot\"]\n",
    "li=pd.DataFrame(data=data, index=index,columns=columns)\n",
    "\n",
    "trot9=trot9.append(li,ignore_index=True)\n",
    "\n",
    "trot9.rename(columns={\"id_quartier\":\"id_quartier\", \"nombrtrot\":\"nombretrot9h\"},inplace=True)\n",
    "trot14=gdf_Tier[gdf_Tier[\"Heure\"]==\"14h\"].groupby('id_quartier',as_index=False).sum()\n",
    "trot14=trot14[[\"id_quartier\",\"nombrtrot\"]]\n",
    "trot14.rename(columns={\"id_quartier\":\"id_quartier\", \"nombrtrot\":\"nombretrot14h\"},inplace=True)\n",
    "trot19=gdf_Tier[gdf_Tier[\"Heure\"]==\"19h\"].groupby('id_quartier',as_index=False).sum()\n",
    "trot19=trot19[[\"id_quartier\",\"nombrtrot\"]]\n",
    "trot19.rename(columns={\"id_quartier\":\"id_quartier\", \"nombrtrot\":\"nombretrot19h\"},inplace=True)\n",
    "trot16=gdf_Tier[gdf_Tier[\"Heure\"]==\"16h\"].groupby('id_quartier',as_index=False).sum()\n",
    "trot16=trot16[[\"id_quartier\",\"nombrtrot\"]]\n",
    "trot16.rename(columns={\"id_quartier\":\"id_quartier\", \"nombrtrot\":\"nombretrot16h\"},inplace=True)\n",
    "trot18=gdf_Tier[gdf_Tier[\"Heure\"]==\"18h\"].groupby('id_quartier',as_index=False).sum()\n",
    "trot18=trot18[[\"id_quartier\",\"nombrtrot\"]]\n",
    "trot18.rename(columns={\"id_quartier\":\"id_quartier\", \"nombrtrot\":\"nombretrot18h\"},inplace=True)\n",
    "gdf4=gdf3.merge(trot9, left_on=\"c_qu\",right_on=\"id_quartier\")\n",
    "gdf4=gdf4.merge(trot14, left_on=\"c_qu\",right_on=\"id_quartier\")\n",
    "gdf4=gdf4.merge(trot19, left_on=\"c_qu\",right_on=\"id_quartier\")\n",
    "gdf4=gdf4.merge(trot16, left_on=\"c_qu\",right_on=\"id_quartier\")\n",
    "gdf4=gdf4.merge(trot18, left_on=\"c_qu\",right_on=\"id_quartier\")\n",
    "gdf4[\"nombretrottotal\"]=gdf4[\"nombretrot9h\"]+gdf4[\"nombretrot14h\"]+gdf4[\"nombretrot19h\"]+gdf4[\"nombretrot18h\"]+gdf4[\"nombretrot16h\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On sauvegarde enfin\n",
    "gdf4.to_csv(path+\"BaseQuartierSa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On a fait de même pour Lundi On va fusionner les bases\n",
    "\n",
    "df=pd.read_csv(path+\"BaseQuartierSa.csv\")\n",
    "df2=pd.read_csv(path+\"BaseQuartierLu.csv\")\n",
    "df[\"Jour\"]=\"Samedi\"\n",
    "df2[\"Jour\"]=\"Lundi\"\n",
    "df3=df.append(df2,ignore_index=True)\n",
    "\n",
    "df3=df3[[ \"Jour\",'c_qu', 'l_qu', 'prop_0-14', 'prop_15-29',\n",
    "       'prop_30-44', 'prop_45-59', 'prop_60-74', 'prop_75+', 'nombre_0-14',\n",
    "       'nombre_15-29', 'nombre_30-44', 'nombre_45-59', 'nombre_60-74', 'nombre_75+',\n",
    "       'pop', 'densite', 'nombretransport',  'numquartier', 'ref',\n",
    "       'nb_logmt_total', 'nombre_de_commerce',  'nombreent',\n",
    "       'CA 1', 'nombretrottotal']]\n",
    "\n",
    "df3.to_csv(path+\"BaseQuartierLuSa.csv\")\n",
    "\n",
    "\n",
    "\n",
    "gdf1=gpd.read_file(path+\"Tierbasefin1geoLu.geojson\")\n",
    "\n",
    "gdf2=gpd.read_file(path+\"Tierbasefin1geoSa.geojson\")\n",
    "\n",
    "gdf3=gdf1.append(gdf2,ignore_index=True)\n",
    "\n",
    "gdf3.to_file(path+\"GeoTierLunsSA.geojson\", driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
